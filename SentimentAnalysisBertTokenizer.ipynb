{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SentimentAnalysisBertTokenizer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6llFE4a2Q/lB+nixiDA6v",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buczekEngineering/Chatbot/blob/main/SentimentAnalysisBertTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEFNeIxrmXCn"
      },
      "source": [
        "# Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ItOz9xAmIml"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KK-A5VzmUIp",
        "outputId": "39daa807-dbee-47df-923e-363659215634"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMVgYxy-ogWM"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDxyeJ5QneyM"
      },
      "source": [
        "# 1. Get the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K_rw0o8nkuA",
        "outputId": "d9e7b294-56a4-4382-ae07-9ff53c16f140"
      },
      "source": [
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ApctlxtwpN"
      },
      "source": [
        "import chardet\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/SentimentData/train.csv\"\n",
        "\n",
        "def check_encoding(data_path): \n",
        "  with open(data_path, \"rb\")as file: \n",
        "    encoding = chardet.detect(file.read(100000000000))\n",
        "    print(encoding)\n",
        "  return encoding[\"encoding\"]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heAwK3IgaL6t"
      },
      "source": [
        "encoding=\"latin1\"\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRiNNmX_qHzt"
      },
      "source": [
        "#encoding = check_encoding(data_path)\n",
        "data = pd.read_csv(data_path, encoding = encoding, header=None, index_col=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7EDctrfaeGC",
        "outputId": "46814359-facf-40dc-ed12-29b65fda65b6"
      },
      "source": [
        "data = data.drop(columns= [1,2,3,4], axis=1)\n",
        "\n",
        "new_columns_names = [\"sentiment\", \"text\"]\n",
        "data.columns = new_columns_names\n",
        "data.columns"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentiment', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ys2uSE5ebwlf",
        "outputId": "b0d8112d-8356-4222-b1ec-a568e87ffee6"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scMdrUNficCF"
      },
      "source": [
        "# 2.Cleaning the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ19RHBHbz8h"
      },
      "source": [
        "def clean_data(tweet): \n",
        "  tweet = re.sub(r\"@[A-Za-z0-9]+\", \" \", tweet)\n",
        "  tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \",tweet)\n",
        "  tweet = re.sub(r\"[^a-zA-Z.!?']\", \" \", tweet)\n",
        "  tweet = re.sub(r\" +\", \" \", tweet)\n",
        "  return tweet.lower()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WRiGcm88cM6S",
        "outputId": "37bd9c78-fb43-4e1d-e48f-9d1ca98e4a0f"
      },
      "source": [
        "data.text = [clean_data(tweet) for tweet in data.text]\n",
        "data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>awww that's a bummer. you shoulda got david c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>i dived many times for the ball. managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no it's not behaving at all. i'm mad. why am ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0   awww that's a bummer. you shoulda got david c...\n",
              "1          0  is upset that he can't update his facebook by ...\n",
              "2          0   i dived many times for the ball. managed to s...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0   no it's not behaving at all. i'm mad. why am ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOYdLl0NhvfR",
        "outputId": "25b67189-5a57-4c43-9b7e-5b05120a3b51"
      },
      "source": [
        "data.sentiment.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U49a5qvGh51T",
        "outputId": "7b66fb0d-80fb-452e-e02d-0fc5c281367f"
      },
      "source": [
        "data.sentiment.loc[data.sentiment == 4] =1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdlhVCfRikoD"
      },
      "source": [
        "# 3.Tokenization, Word2Int, Shuffling, Padding, Converting to Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MGswcFRiMI6"
      },
      "source": [
        "# Wraps a SavedModel as a Keras Layer, to have access to meta data for the tokenizer (like vocab size).\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "# extract bert vocab size\n",
        "vocab_size = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "\n",
        "\n",
        "def create_tokenizer(vocab_size, do_lower_case): \n",
        "  FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "  tokenizer = FullTokenizer(vocab_size, do_lower_case)\n",
        "  return tokenizer\n",
        "\n",
        "tokenizer = create_tokenizer(vocab_size, do_lower_case)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqd7AQBBooxA"
      },
      "source": [
        "# tokenize the sequence and convert words to id\n",
        "def tokenize_tweets(tweet): \n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweet))\n",
        "\n",
        "data_input = [tokenize_tweets(tweet) for tweet in data.text]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yevrhS67xSNO"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"data_input.pickle\", \"wb\") as file: \n",
        "  pickle.dump(data_input, file)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a_BzMNvsLoK"
      },
      "source": [
        "labels_input = data.sentiment.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAR0c_x2ygEj",
        "outputId": "8c34e7b6-f155-4c25-d44d-c4ee3fe80902"
      },
      "source": [
        "with open(\"data_input.pickle\", \"rb\") as f: \n",
        "  loaded_data = pickle.load(f)\n",
        "print(loaded_data[6])\n",
        "print(labels_input[6])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2342, 1037, 8549]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwjdSprrqskR"
      },
      "source": [
        "# put encoded/tokenized data and lables into a list\n",
        "\n",
        "encoded_data = [[tweet, labels_input[i], len(tweet)] for i, tweet in enumerate(loaded_data)]\n",
        "\n",
        "random.shuffle(encoded_data)\n",
        "\n",
        "#[[[2054, 1045, 2081, 2005, 4596], 1],....]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGCsKhdItFfO"
      },
      "source": [
        "# we will sort the data so that the sequences with similar size will be padded together\n",
        "encoded_data.sort(key= lambda x: x[2])\n",
        "sorted_all = [(ele[0], ele[1]) for ele in encoded_data if ele[2]>7]\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPaZFMP6zkWR",
        "outputId": "0b20b458-772a-4a73-be5a-5112bee010ee"
      },
      "source": [
        "print(sorted_all[1])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([1996, 3712, 3504, 2061, 12459, 2157, 2085, 1012], 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXlHzqDK8Ff"
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_HpOPj7LAMq",
        "outputId": "ba7103a2-9214-4337-b077-3638f265ad2c"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=int32, numpy=\n",
              " array([ 1045,  2064,  2102,  2424,  2026,  4950, 11057,  1040],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFV33yL2LQFg",
        "outputId": "b16937b3-6960-461d-83da-d6b82ef052d8"
      },
      "source": [
        "print(all_dataset)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FlatMapDataset shapes: (<unknown>, <unknown>), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P9Jhus5xltA",
        "outputId": "7b82068e-b408-4883-cf2f-53eacdfa5ec1"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "all_padded = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None,), ()))\n",
        "print(all_padded)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PaddedBatchDataset shapes: ((None, None), (None,)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD1mi-LJME2Y"
      },
      "source": [
        "test_size = 20\n",
        "NB_BATCHES = math.ceil(len(encoded_data)/ BATCH_SIZE)\n",
        "all_padded.shuffle(NB_BATCHES)\n",
        "training_data = all_padded.skip(test_size)\n",
        "test_data = all_padded.take(test_size)\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bYT3iRf5qM_"
      },
      "source": [
        "# 4. Building Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btydKrwL5mSX"
      },
      "source": [
        "class CNN(tf.keras.Model): \n",
        "  def __init__(self, vocab_size, embedding_dim = 64, nb_filters =50, FFN_units = 512, nb_classes=2, dropout_rate = 0.5, training=False, name=\"cnn\"):\n",
        "    super(CNN, self).__init__(name=name)\n",
        "\n",
        "    self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2, padding=\"valid\", activation=\"relu\")\n",
        "    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size=3, padding=\"valid\", activation=\"relu\")\n",
        "    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4, padding=\"valid\", activation=\"relu\")\n",
        "\n",
        "    self.maxPooling = layers.GlobalMaxPooling1D()\n",
        "\n",
        "    self.dense = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "    self.dropout = layers.Dropout(rate=dropout_rate) \n",
        "    if nb_classes == 2: \n",
        "      self.final_dense = layers.Dense(1, activation=\"sigmoid\")\n",
        "    else: \n",
        "      self.final_dense = layers.Dense(nb_classes, activation=\"softmax\")\n",
        "\n",
        "  \n",
        "  def call(self, inputs, training):\n",
        "      x = self.embedding(inputs)\n",
        "      x_1 = self.bigram(x) \n",
        "      x_1 = self.maxPooling(x_1) \n",
        "      x_2 = self.trigram(x) \n",
        "      x_3 = self.fourgram(x) \n",
        "      x_3 = self.maxPooling(x_3)\n",
        "      \n",
        "      merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "      merged = self.dense(merged)\n",
        "      merged = self.dropout(merged, training)\n",
        "      output = self.final_dense(merged)\n",
        "      \n",
        "      return output\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQsUbVbO-Ine"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 64\n",
        "NB_FILTERS = 50\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "DROPOUT_RATE = 0.5\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK3jdKTZ-UML"
      },
      "source": [
        "classifier = CNN(vocab_size=VOCAB_SIZE,\n",
        "            embedding_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLuZVgYj_OhT"
      },
      "source": [
        "classifier.compile(\n",
        "    loss = \"binary_crossentropy\",\n",
        "    optimizer =\"adam\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GgFNifq_eWW"
      },
      "source": [
        "checkpoint_path = \"./drive/My Drive/projects/BERT/ckpt_bert_tok/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(classifier=classifier)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!!\")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaRl_Dc8_7oA"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZM_ZHNOLwcC"
      },
      "source": [
        "# 5. Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GijIHX3S_t4c",
        "outputId": "c7f358b9-7a13-4c8e-ad59-c22173c75f95"
      },
      "source": [
        "classifier.fit(training_data, epochs=NB_EPOCHS)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "165549/165549 [==============================] - 2798s 17ms/step - loss: 0.4187 - accuracy: 0.8117\n",
            "Epoch 2/5\n",
            "165549/165549 [==============================] - 2795s 17ms/step - loss: 0.3800 - accuracy: 0.8363\n",
            "Epoch 3/5\n",
            "165549/165549 [==============================] - 2733s 17ms/step - loss: 0.3689 - accuracy: 0.8436\n",
            "Epoch 4/5\n",
            "165549/165549 [==============================] - 2712s 16ms/step - loss: 0.3606 - accuracy: 0.8491\n",
            "Epoch 5/5\n",
            "165549/165549 [==============================] - 2699s 16ms/step - loss: 0.3555 - accuracy: 0.8527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa7b7730590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtL_L8vRL2_x"
      },
      "source": [
        "# 6. Evaluating "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgT8aCJ8CgsA"
      },
      "source": [
        "# tokenize the sequence and convert words to id\n",
        "def tokenize_tweets(tweet): \n",
        "  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweet))\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIWORy10mhLn",
        "outputId": "8a1f44e2-73b4-4b6b-809b-368be3058d75"
      },
      "source": [
        "def check_sentiment(sentence): \n",
        "  tokens = tokenize_tweets(sentence)\n",
        "  input = tf.expand_dims(tokens, 0)\n",
        "\n",
        "  prediction = classifier(input, training=False)\n",
        "  sentiment = math.floor(prediction*2)\n",
        "\n",
        "  if sentiment == 0: \n",
        "    print(\"Output of the model: {}. \\nPredicted sentiment: negative\".format(prediction))\n",
        "\n",
        "  elif sentiment == 1: \n",
        "    print(\"Output of the model: {}\\nPredicted sentiment: positive\".format(prediction))\n",
        "\n",
        "check_sentiment(\"love you my sugarboo\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output of the model: [[0.9627555]]\n",
            "Predicted sentiment: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VA4TkEAD_uX",
        "outputId": "3997794a-a8bf-4376-e633-a95d5eddb9be"
      },
      "source": [
        "eval_result = classifier.evaluate(test_data)\n",
        "print(eval_result)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8250\n",
            "[0.3686465322971344, 0.824999988079071]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}